(1 | Commission_speakerinfo),
data = final_data,
family = binomial,
control = glmerControl(optimizer = "bobyqa"))
summary(logit_glmm_5)
# Model Comparison
AIC(logit_glmm_1, logit_glmm_2, logit_glmm_3, logit_glmm_4, logit_glmm_5, logit_glmm_6)
# Define the list of logistic GLMM models
logit_models <- list(
"Model 1" = logit_glmm_1,
"Model 2" = logit_glmm_2,
"Model 3" = logit_glmm_3,
"Model 4" = logit_glmm_4,
"Model 5" = logit_glmm_5,
"Model 6" = logit_glmm_6
)
# Generate a logistic GLMM regression table
modelsummary(logit_models,
stars = TRUE,
title = "Logistic GLMM Regression Results",
gof_omit = "IC|Log|Deviance")
plot(ggpredict(logit_glmm_6, terms = c("PortfolioEU_speakerinfo", "Sex_speakerinfo")))
# Get predicted values for the interaction effect
predicted_values <- ggpredict(logit_glmm_6, terms = c("PortfolioEU_speakerinfo", "Sex_speakerinfo"))
# Rename factor levels for clarity
predicted_values$x <- factor(predicted_values$x,
levels = c(1, 2, 3),
labels = c("Masculine", "Neutral", "Feminine"))
predicted_values$group <- factor(predicted_values$group,
levels = c(0, 1),
labels = c("Men", "Women"))
# Create the scatter plot with 95% CIs
# Install/load required packages
# Get predicted values for the interaction effect
predicted_values <- ggpredict(logit_glmm_6, terms = c("PortfolioEU_speakerinfo", "Sex_speakerinfo"))
# Rename factor levels for clarity
predicted_values$x <- factor(predicted_values$x,
levels = c(1, 2, 3),
labels = c("Masculine", "Neutral", "Feminine"))
predicted_values$group <- factor(predicted_values$group,
levels = c(0, 1),
labels = c("Men", "Women"))
# Create the scatter plot with thicker error bars and a black frame
plot1 <- ggplot(predicted_values, aes(x = x, y = predicted, color = group)) +
geom_point(size = 4, position = position_dodge(width = 0.3)) +  # Scatter points, slightly dodged
geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2, size = 1.3,  # Thicker error bars
position = position_dodge(width = 0.3), alpha = 0.8) +
scale_color_manual(values = c("Men" = "#003399", "Women" = "#FFCC00")) +  # Custom colors
labs(
x = "Portfolio-Group",
y = "Pred. Prob. of Making a Claim",
color = "Sex Commissioner",
title = "Interaction of Portfolio and Sex on Claim-Making Probability"
) +
theme_minimal() +  # Clean theme
theme(
text = element_text(size = 12),
legend.position = "bottom",
legend.title = element_text(face = "bold"),
legend.text = element_text(size = 12),
panel.grid.major = element_blank(),  # Remove all background grid lines
panel.grid.minor = element_blank(),
panel.border = element_rect(color = "black", fill = NA, size = 0.1)  # Black frame around the plot
)
save_folder <- "C:/Users/User/Documents/plots/"
ggsave(filename = paste0(save_folder, "Interaction Effect Portfolio Sex BinaryEU.svg"), plot = plot1, width = 8, height = 6, dpi = 300, device = "svg")
# Baseline Model: Portfolio Only
zinb_glmm_1 <- glmmTMB(claimcount ~ PortfolioEU_speakerinfo +
(1 | Commission_speakerinfo),
data = final_data,
family = nbinom2,
ziformula = ~1,  # Simplified zero-inflation model
control = glmmTMBControl(optimizer = optim, optArgs = list(method = "BFGS")))
# Add Length
zinb_glmm_2 <- glmmTMB(claimcount ~ PortfolioEU_speakerinfo + length +
(1 | Commission_speakerinfo),
data = final_data,
family = nbinom2,
ziformula = ~1,
control = glmmTMBControl(optimizer = optim, optArgs = list(method = "BFGS")))
# Add w_top_tot
zinb_glmm_3 <- glmmTMB(claimcount ~ PortfolioEU_speakerinfo + length + w_top_tot +
(1 | Commission_speakerinfo),
data = final_data,
family = nbinom2,
ziformula = ~1,
control = glmmTMBControl(optimizer = optim, optArgs = list(method = "BFGS")))
# Add European Party (Matches logit_glmm_4)
zinb_glmm_4 <- glmmTMB(claimcount ~ PortfolioEU_speakerinfo + length + European.Party_speakerinfo +
(1 | Commission_speakerinfo),
data = final_data,
family = nbinom2,
ziformula = ~1,
control = glmmTMBControl(optimizer = optim, optArgs = list(method = "BFGS")))
# Add Interaction: Portfolio * Sex (Matches logit_glmm_5)
zinb_glmm_5 <- glmmTMB(claimcount ~ PortfolioEU_speakerinfo * Sex_speakerinfo + length + European.Party_speakerinfo +
(1 | Commission_speakerinfo),
data = final_data,
family = nbinom2,
ziformula = ~1,
control = glmmTMBControl(optimizer = optim, optArgs = list(method = "BFGS")))
# Add w_top_tot (Matches logit_glmm_6)
zinb_glmm_6 <- glmmTMB(claimcount ~ PortfolioEU_speakerinfo * Sex_speakerinfo + length + European.Party_speakerinfo + w_top_tot +
(1 | Commission_speakerinfo),
data = final_data,
family = nbinom2,
ziformula = ~1,
control = glmmTMBControl(optimizer = optim, optArgs = list(method = "BFGS")))
# Model Summaries
summary(zinb_glmm_6)
# Model Comparison
AIC(zinb_glmm_1, zinb_glmm_2, zinb_glmm_3, zinb_glmm_4, zinb_glmm_5, zinb_glmm_6)
# Define the list of ZINB GLMM models
zinb_models <- list(
"Model 1" = zinb_glmm_1,
"Model 2" = zinb_glmm_2,
"Model 3" = zinb_glmm_3,
"Model 4" = zinb_glmm_4,
"Model 5" = zinb_glmm_5,
"Model 6" = zinb_glmm_6
)
# Generate a ZINB regression table
modelsummary(zinb_models,
stars = TRUE,
shape = term ~ model + component,  # Separates conditional & zero-inflation coefficients
title = "Zero-Inflated Negative Binomial GLMM Results",
gof_omit = "IC|Log|Deviance")
logit_glmm_time <- glmer(claimbinary ~ PortfolioEU_speakerinfo * Sex_speakerinfo + length + European.Party_speakerinfo + w_top_tot +
factor(Commission_speakerinfo) +  # Treat Commission as a fixed effect
(1 | speaker.name),  # Keep nesting at the speaker level
data = final_data,
family = binomial,
control = glmerControl(optimizer = "bobyqa"))
summary(logit_glmm_time)
zinb_glmm_time <- glmmTMB(claimcount ~ PortfolioEU_speakerinfo * Sex_speakerinfo + length + European.Party_speakerinfo + w_top_tot +
factor(Commission_speakerinfo) +  # Fixed effect for Commission
(1 | speaker.name),  # Keep nesting at speaker level
data = final_data,
family = nbinom2,
ziformula = ~1,
control = glmmTMBControl(optimizer = optim, optArgs = list(method = "BFGS")))
summary(zinb_glmm_time)
# Get predicted values over time
predicted_values <- ggpredict(logit_glmm_time, terms = c("PortfolioEU_speakerinfo", "Sex_speakerinfo", "Commission_speakerinfo"))
library(dplyr)
library(lubridate)
# Ensure SpeechDate is in Date format
final_data$SpeechDate <- as.Date(final_data$SpeechDate, format = "%Y-%m-%d")
# Ensure SpeechDate is in Date format
final_data$SpeechDate <- as.Date(final_data$date, format = "%Y-%m-%d")
# Define function to calculate lag variables
compute_lag <- function(data, time_window) {
data %>%
arrange(Reassigned_Topic, SpeechDate) %>%  # Sort by topic and date
group_by(Reassigned_Topic) %>%
mutate(
women_topic_lag = lag(any(Sex_speakerinfo == 1 & SpeechDate >= (SpeechDate - weeks(time_window))), default = 0),
women_claim_lag = lag(any(Sex_speakerinfo == 1 & claimbinary == 1 & SpeechDate >= (SpeechDate - weeks(time_window))), default = 0)
) %>%
ungroup()
}
# Generate lag variables for different windows (1, 2, 3, 4, 5 weeks)
for (w in 1:5) {
final_data <- compute_lag(final_data, time_window = w)
colnames(final_data)[ncol(final_data) - 1] <- paste0("women_topic_lag_", w, "w")
colnames(final_data)[ncol(final_data)] <- paste0("women_claim_lag_", w, "w")
}
library(lme4)
# Filter for male speakers only
male_speeches <- final_data %>% filter(Sex_speakerinfo == 0)
# Fit models for different lags
models <- list()
for (w in 1:5) {
formula <- as.formula(paste0("claimbinary ~ women_topic_lag_", w, "w + women_claim_lag_", w, "w +
PortfolioG_speakerinfo + length + European.Party_speakerinfo +
factor(speaker.name) +  # Speaker Fixed Effect
(1 | Commission_speakerinfo)"))
models[[paste0("logit_glmm_", w, "w")]] <- glmer(formula, data = male_speeches, family = binomial, control = glmerControl(optimizer = "bobyqa"))
}
# Compare AIC scores
AIC_results <- sapply(models, AIC)
print(AIC_results)
# Select best model (lowest AIC)
best_lag <- which.min(AIC_results)
best_model <- models[[best_lag]]
summary(best_model)
for (w in 1:5) {
formula <- as.formula(paste0("claimbinary ~ women_topic_lag_", w, "w + women_claim_lag_", w, "w +
PortfolioG_speakerinfo + length + European.Party_speakerinfo +
(1 | Commission_speakerinfo)"))
models[[paste0("logit_glmm_", w, "w")]] <- glmer(formula, data = male_speeches, family = binomial, control = glmerControl(optimizer = "bobyqa"))
}
# Compare AIC scores
AIC_results <- sapply(models, AIC)
print(AIC_results)
# Select best model (lowest AIC)
best_lag <- which.min(AIC_results)
best_model <- models[[best_lag]]
summary(best_model)
library(car)
vif(glm(claimbinary ~ women_topic_lag_1w + women_claim_lag_1w +
PortfolioG_speakerinfo + length + European.Party_speakerinfo,
data = male_speeches, family = binomial))
summary(male_speeches[, c("women_topic_lag_1w", "women_claim_lag_1w",
"women_topic_lag_2w", "women_claim_lag_2w",
"women_topic_lag_3w", "women_claim_lag_3w")])
# Define time window in weeks
time_window <- 3  # Try 1, 2, 3, 4, 5 weeks
male_speeches <- final_data %>%
filter(Sex_speakerinfo == 0) %>%
group_by(speaker.name, Reassigned_Topic) %>%
mutate(
women_topic_lag_count = sum(Sex_speakerinfo == 1 &
SpeechDate >= (SpeechDate - weeks(time_window)), na.rm = TRUE),
women_claim_lag_count = sum(Sex_speakerinfo == 1 & claimbinary == 1 &
SpeechDate >= (SpeechDate - weeks(time_window)), na.rm = TRUE)
) %>%
ungroup()
logit_glmm_opt <- glmer(claimbinary ~ women_topic_lag_count + women_claim_lag_count +
PortfolioG_speakerinfo + length_scaled + European.Party_speakerinfo +
(1 | Commission_speakerinfo),
data = male_speeches,
family = binomial,
control = glmerControl(optimizer = "bobyqa"))
summary(logit_glmm_opt)
library(car)
# Fit a simple logistic regression to check VIF
vif(glm(claimbinary ~ women_topic_lag_count + women_claim_lag_count +
PortfolioG_speakerinfo + length_scaled + European.Party_speakerinfo,
data = male_speeches,
family = binomial))
alias(glm(claimbinary ~ women_topic_lag_count + women_claim_lag_count +
PortfolioG_speakerinfo + length_scaled + European.Party_speakerinfo,
data = male_speeches,
family = binomial))
cor(male_speeches$women_topic_lag_count, male_speeches$women_claim_lag_count, use = "complete.obs")
logit_glmm_fix <- glmer(claimbinary ~ women_claim_lag_count +
PortfolioG_speakerinfo + length_scaled + European.Party_speakerinfo +
(1 | Commission_speakerinfo),
data = male_speeches,
family = binomial,
control = glmerControl(optimizer = "bobyqa"))
summary(logit_glmm_fix)
compute_lags <- function(data, time_window) {
data %>%
arrange(SpeechDate) %>%
group_by(Reassigned_Topic) %>%
mutate(
women_topic_lag = sapply(row_number(), function(i) {
if(i == 1) return(FALSE)
current_date <- SpeechDate[i]
any(Sex_speakerinfo[1:(i-1)] == 1 &
SpeechDate[1:(i-1)] >= (current_date - weeks(time_window)))
}),
women_claim_lag = sapply(row_number(), function(i) {
if(i == 1) return(FALSE)
current_date <- SpeechDate[i]
any(Sex_speakerinfo[1:(i-1)] == 1 & claimbinary[1:(i-1)] == 1 &
SpeechDate[1:(i-1)] >= (current_date - weeks(time_window)))
})
) %>%
ungroup()
}
# We'll join new lag columns back to the original data using the unique row_id
final_data_lag <- final_data
for (w in 1:5) {
tmp <- compute_lags(final_data, time_window = w) %>%
select(row_id, women_topic_lag, women_claim_lag) %>%
rename(!!paste0("women_topic_lag_", w, "w") := women_topic_lag,
!!paste0("women_claim_lag_", w, "w") := women_claim_lag)
final_data_lag <- left_join(final_data_lag, tmp, by = "row_id")
}
# Compare AIC scores for the different lag windows
AIC_results <- sapply(models, AIC)
print(AIC_results)
# Select best model (lowest AIC)
best_lag_index <- which.min(AIC_results)
best_model <- models[[best_lag_index]]
summary(best_model)
# Fit a GLMM using the count variables
logit_glmm_opt <- glmer(claimbinary ~ women_topic_lag_count +
PortfolioG_speakerinfo + length_scaled + European.Party_speakerinfo +
(1 | Commission_speakerinfo),
data = male_speeches_counts,
family = binomial,
control = glmerControl(optimizer = "bobyqa"))
male_speeches_counts <- compute_lag_counts(male_speeches_counts, time_window)
compute_lag_counts <- function(data, time_window) {
data %>%
arrange(SpeechDate) %>%
group_by(speaker.name, Reassigned_Topic) %>%
mutate(
women_topic_lag_count = sapply(row_number(), function(i) {
if(i == 1) return(0)
current_date <- SpeechDate[i]
sum(Sex_speakerinfo[1:(i-1)] == 1 &
SpeechDate[1:(i-1)] >= (current_date - weeks(time_window)))
}),
women_claim_lag_count = sapply(row_number(), function(i) {
if(i == 1) return(0)
current_date <- SpeechDate[i]
sum(Sex_speakerinfo[1:(i-1)] == 1 & claimbinary[1:(i-1)] == 1 &
SpeechDate[1:(i-1)] >= (current_date - weeks(time_window)))
})
) %>%
ungroup()
}
# Define the time window (e.g., 3 weeks)
time_window <- 3
male_speeches_counts <- final_data %>%
filter(Sex_speakerinfo == 0) %>%
mutate(row_id = row_number())  # in case a new unique id is needed
male_speeches_counts <- compute_lag_counts(male_speeches_counts, time_window)
# Fit a GLMM using the count variables
logit_glmm_opt <- glmer(claimbinary ~ women_topic_lag_count +
PortfolioG_speakerinfo + length_scaled + European.Party_speakerinfo +
(1 | Commission_speakerinfo),
data = male_speeches_counts,
family = binomial,
control = glmerControl(optimizer = "bobyqa"))
summary(logit_glmm_opt)
# Check VIF for the count model
vif(glm(claimbinary ~ women_topic_lag_count +
PortfolioG_speakerinfo + length_scaled + European.Party_speakerinfo,
data = male_speeches_counts,
family = binomial))
sum(final_data$claimbinary)
# Load libraries
library(rdrobust)
library(lme4)
library(broom.mixed)
library(ggplot2)
library(dplyr)
library(dplyr)
# Convert date variable to Date format (assuming "date" column exists in dataset)
final_data$date <- as.Date(final_data$date, format="%Y-%m-%d")
# Define event date (cutoff) for RDD
event_date <- as.Date("1996-02-01")
# Create a running variable (time to event in months)
final_data$time_to_event <- as.numeric(difftime(final_data$date, event_date, units = "days")) / 30.44  # Convert to months
# Create an indicator for being after the event
final_data$post_event <- ifelse(final_data$time_to_event >= 0, 1, 0)
# ------------------------------------
# **1️⃣ Logistic Regression with RDD**
# ------------------------------------
logit_rdd <- glmer(claimbinary ~ time_to_event + post_event + time_to_event:post_event +
Sex_speakerinfo,
data = final_data,
family = binomial,
control = glmerControl(optimizer = "bobyqa"))
# Convert date variable to Date format (assuming "date" column exists in dataset)
final_data$date <- as.Date(final_data$date, format="%Y-%m-%d")
# Define event date (cutoff) for RDD
event_date <- as.Date("1996-02-01")
# Create a running variable (time to event in months)
final_data$time_to_event <- as.numeric(difftime(final_data$date, event_date, units = "days")) / 30.44  # Convert to months
# Create an indicator for being after the event
final_data$post_event <- ifelse(final_data$time_to_event >= 0, 1, 0)
# ------------------------------------
# **1️⃣ Logistic Regression with RDD (No Random Effects)**
# ------------------------------------
logit_rdd <- glm(claimbinary ~ time_to_event + post_event + time_to_event:post_event +
Sex_speakerinfo + post_event:Sex_speakerinfo,
data = final_data,
family = binomial)
summary(logit_rdd)
# ------------------------------------
# **2️⃣ RDD Model using `rdrobust`**
# ------------------------------------
# Select the bandwidth automatically
bw <- rdbwselect(y = final_data$claimbinary, x = final_data$time_to_event, c = 0)
# ------------------------------------
# **2️⃣ RDD Model using `rdrobust`**
# ------------------------------------
# Select the bandwidth automatically
bw <- rdbwselect(y = final_data$claimbinary, x = final_data$time_to_event, c = 0, bwselect = "msetwo")
# Run RDD using `rdrobust`
rdd_results <- rdrobust(y = final_data$claimbinary, x = final_data$time_to_event, c = 0, p = 1, bwselect = "msetwo")
# Print results
summary(rdd_results)
# Convert date variable to Date format (assuming "date" column exists in dataset)
final_data$date <- as.Date(final_data$date, format="%Y-%m-%d")
# Define event date (cutoff) for RDD
event_date <- as.Date("1996-02-01")
# Create a running variable (time to event in **DAYS**)
final_data$time_to_event <- as.numeric(difftime(final_data$date, event_date, units = "days"))
# Create an indicator for being after the event
final_data$post_event <- ifelse(final_data$time_to_event >= 0, 1, 0)
# Restrict dataset to ±8 years (±2920 days) around event
final_data <- final_data %>% filter(time_to_event >= -2920 & time_to_event <= 2920)
# ------------------------------------
# **1️⃣ Logistic Regression with RDD (No Random Effects)**
# ------------------------------------
logit_rdd <- glm(claimbinary ~ time_to_event + post_event + time_to_event:post_event +
Sex_speakerinfo + post_event:Sex_speakerinfo,
data = final_data,
family = binomial)
summary(logit_rdd)
# ------------------------------------
# **2️⃣ RDD Model using `rdrobust`**
# ------------------------------------
# Select bandwidth using an improved method for discrete data
bw <- rdbwselect(y = final_data$claimbinary, x = final_data$time_to_event, c = 0, bwselect = "msetwo")
# Run RDD using local polynomial regression
rdd_results <- rdrobust(y = final_data$claimbinary, x = final_data$time_to_event, c = 0, p = 1, h = 2920, bwselect = "msetwo")
# Print results
summary(rdd_results)
# Bin the data into 180-day intervals (~6 months) for plotting
rdd_plot_data <- final_data %>%
mutate(bin = cut(time_to_event, breaks = seq(min(time_to_event), max(time_to_event), by = 180))) %>%
group_by(bin, post_event, Sex_speakerinfo) %>%
summarize(avg_claim = mean(claimbinary, na.rm = TRUE),
se = sd(claimbinary, na.rm = TRUE) / sqrt(n()))
# Convert bin to numeric for plotting
rdd_plot_data$bin <- as.numeric(gsub("[^0-9.-]", "", rdd_plot_data$bin))
# Plot RDD results by Sex
ggplot(rdd_plot_data, aes(x = bin, y = avg_claim, color = as.factor(post_event), shape = as.factor(Sex_speakerinfo))) +
geom_point(size = 3) +
geom_smooth(method = "lm", se = FALSE) +
scale_color_manual(values = c("0" = "#003399", "1" = "#FFCC00"),
labels = c("Before Feb 1996", "After Feb 1996")) +
scale_shape_manual(values = c(16, 17), labels = c("Men", "Women")) +
labs(title = "Regression Discontinuity: Claim Probability Before & After Feb 1996 by Speaker Sex",
x = "Time to Event (Days)",
y = "Average Probability of Making a Claim",
color = "Period",
shape = "Speaker Sex") +
theme_minimal() +
geom_vline(xintercept = 0, linetype = "dashed", color = "black", size = 1) +
annotate("text", x = -2000, y = max(rdd_plot_data$avg_claim), label = "Pre-Feb 1996", hjust = 1, size = 5, color = "#003399") +
annotate("text", x = 2000, y = max(rdd_plot_data$avg_claim), label = "Post-Feb 1996", hjust = 0, size = 5, color = "#FFCC00")
# Load libraries
library(modelsummary)
library(kableExtra)
# Create a summary table of the RD regression model
rd_table <- modelsummary(list("Logistic RDD" = logit_rdd),
stars = TRUE,
title = "Regression Discontinuity Estimates (Logistic Model)",
coef_map = c("time_to_event" = "Time to Event (Days)",
"post_event" = "Post-Feb 1996",
"time_to_event:post_event" = "Interaction: Time x Post Event",
"Sex_speakerinfo" = "Speaker Sex (Women)",
"post_event:Sex_speakerinfo" = "Interaction: Post Event x Sex"),
gof_map = c("nobs" = "Number of Observations",
"aic" = "AIC",
"bic" = "BIC"),
output = "html")  # Change to "latex" for LaTeX format
# Save table as an HTML file
writeLines(rd_table, "RD_Model_Summary.html")
# Print the table in the R console
rd_table
sum(dffinal$claim)
sum(dffinal$claim==TRUE)
modelsummary(best_model)
library(ggplot2)
# Create the plot
ggplot(dffinal, aes(x = length)) +
geom_histogram(binwidth = 10, fill = "#003399", color = "white", alpha = 0.8) +  # Adjust binwidth as needed
labs(title = "Distribution of Length",
x = "Length",
y = "Frequency") +
theme_minimal() +
scale_color_manual(values = c("0" = "#003399", "1" = "#FFCC00"),
labels = c("Before Feb 1996", "After Feb 1996")) +
geom_vline(xintercept = mean(dffinal$length, na.rm = TRUE),
linetype = "dashed", color = "black", size = 1) +
annotate("text", x = quantile(dffinal$length, 0.1, na.rm = TRUE),
y = max(table(dffinal$length)),
label = "Left Tail", hjust = 1, size = 5, color = "#003399") +
annotate("text", x = quantile(dffinal$length, 0.9, na.rm = TRUE),
y = max(table(dffinal$length)),
label = "Right Tail", hjust = 0, size = 5, color = "#FFCC00")
library(ggplot2)
ggplot(dffinal, aes(x = length)) +
geom_histogram(binwidth = 10, fill = "#003399", color = "white", alpha = 0.8) +  # Dark blue bars
labs(title = "Distribution of Length",
x = "Length",
y = "Frequency") +
theme_minimal()
ggplot(safe, aes(x = length)) +
geom_histogram(binwidth = 10, fill = "#003399", color = "white", alpha = 0.8) +  # Dark blue bars
labs(title = "Distribution of Length",
x = "Length",
y = "Frequency") +
theme_minimal()
ggplot(safe, aes(y = length)) +
geom_boxplot(fill = "#FFCC00", color = "#003399") +  # Yellow box, blue outline
labs(title = "Boxplot of Length",
y = "Length") +
theme_minimal()
ggplot(dffinal, aes(y = length)) +
geom_boxplot(fill = "#FFCC00", color = "#003399", outlier.color = "#003399", outlier.shape = 16, outlier.size = 2) +
labs(title = "Distribution of Length",
y = "Length") +
theme_minimal() +
theme(axis.title.x = element_blank(),  # Remove x-axis label
axis.text.x = element_blank(),   # Remove x-axis values
axis.ticks.x = element_blank()) +  # Remove x-axis ticks
coord_flip()  # Makes the boxplot horizontal for better readability
summary(safe$length)
setwd("C:/Users/User/Downloads/Corpora_PLS_austria_IBK/claimR")
devtools::document()
setwd("C:/Users/User/Downloads/Corpora_PLS_austria_IBK/claimR")
devtools::document()
setwd("C:/Users/User/Downloads/Corpora_PLS_austria_IBK/claimR")
devtools::document()
use_python("C:/Users/User/AppData/Local/Programs/Python/Python313/python.exe", required = TRUE)
reticulate::py_config()
reticulate::py_module_available("numpy")
reticulate::py_config()
use_python("C:/Users/User/AppData/Local/Programs/Python/Python313/python.exe", required = TRUE)
reticulate::py_config()
